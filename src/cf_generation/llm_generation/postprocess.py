import jsonlines
from tqdm import tqdm
from datasets import load_dataset
import os


# BASE_PATH = "/home/sachdeva/projects/ukp/exp_calibration/"
BASE_PATH = "/storage/ukp/work/sachdeva/research_projects/exp_calibration/"


def postprocess_question(question):
    # question = question.strip()
    """Postprocess the questions to remove the question type and the question mark."""
    tokens_to_remove = ["[", "'", '"', "]"]
    # Create a translation table that maps each unwanted token to None
    translator = str.maketrans({token: None for token in tokens_to_remove})
    ques = question.translate(translator).strip()
    # check if the question words are less than 3
    if len(ques.split()) < 3:
        return None
    # question corrector
    # Define a dictionary to map misspelled words to correct words
    corrections = {
        "ho": "who",
        "hat": "what",
        "hich": "which",
        "ow": "how",
        "ich": "which",
        "here": "where",
        "hen": "when",
    }
    # if question starts with a misspelled word, replace it with the correct word
    # print("Question before correction: ", ques.split())0])
    if ques.split()[0].lower() in list(corrections.keys()):
        ques = ques.replace(ques.split()[0], corrections[ques.split()[0]])
        ques = ques.capitalize()
    return ques


def postprocess_answer(answer):
    """Postprocess the answer to remove the answer type."""
    if answer == " ":
        return None
    return answer


def remove_duplicate_examples(input_file, output_file):
    # Load SQuAD dataset
    squad_dataset = load_dataset("squad")

    # Collect all unique QA strings in SQuAD dataset
    squad_examples = set()
    for example in squad_dataset["train"]:
        qa_string = example["question"] + example["answers"]["text"][0]
        squad_examples.add(qa_string)

    seen_examples = set()

    with jsonlines.open(output_file, "w") as writer:
        with jsonlines.open(input_file) as reader:
            for example in tqdm(reader):
                qa_string = example["question"] + example["answers"]["text"][0]
                if qa_string not in seen_examples and qa_string not in squad_examples:
                    writer.write(example)
                    seen_examples.add(qa_string)


def postprocess_pipeline(data_path, save_path, model_name):
    """
    Postprocess the data generated by the pipeline
    """

    # step 1: collate all the data from the jsonl files
    from src.cf_generation.llm_generation.utils import collate_jsonl_files

    collate_jsonl_files(
        data_path, os.path.join(save_path, f"{model_name}_collated_data.jsonl")
    )
    print(
        "Collated data saved to: ",
        os.path.join(save_path, f"{model_name}_collated_data.jsonl"),
    )

    seen_examples = set()
    total = 0
    # filter out samples with same ids
    with jsonlines.open(
        os.path.join(save_path, f"{model_name}_collated_data_cleaned.jsonl"), "w"
    ) as writer:
        with jsonlines.open(
            os.path.join(save_path, f"{model_name}_collated_data.jsonl")
        ) as reader:
            for example in tqdm(reader):
                id = example["id"].split("_")[0]
                total += 1
                if id not in seen_examples:
                    writer.write(example)
                    seen_examples.add(id)
    print("Total samples before cleaning: ", total)
    print("Total samples after cleaning: ", len(seen_examples))

    # step 2: get the answer indices
    from src.cf_generation.llm_generation.utils import get_answer_start, save_to_disk

    data_type = "counterfactuals"
    if data_type == "squad":
        # load squad data
        dataset = load_dataset("squad", "plain_text")
        train_data = dataset["train"]
        data = [
            sample
            for sample in tqdm(
                train_data, total=len(train_data), desc="Loading SQuAD data ... "
            )
        ]
    elif data_type == "counterfactuals":
        # read in counterfactual data from jsonl file
        with jsonlines.open(
            os.path.join(save_path, f"{model_name}_collated_data_cleaned.jsonl")
        ) as reader:
            data = [
                sample
                for sample in tqdm(
                    reader, desc="Loading Counterfactual data for answer gen. ... "
                )
            ]

            # assert if data length is equal to the number of unique samples via the id
            assert len(data) == len(set([sample["id"] for sample in data]))

    no_answer_found = 0
    c = 0
    samples = []
    for example in tqdm(data):
        try:
            c += 1

            # print("question: ", example["question"])
            # print("context: ", example["context"])
            # print("answer: ", answer)
            # print("-" * 100)

            answer_start = get_answer_start(
                example["question"], example["context"], example["answer"]
            )
            if answer_start == -1:
                no_answer_found += 1
                continue
            samples.append(
                {
                    "id": example["id"],
                    "question": example["question"],
                    "context": example["context"],
                    "answers": {
                        "text": [example["answer"]],
                        "answer_start": [answer_start],
                        "answer_end": [answer_start + len(example["answer"])],
                    },
                },
            )
            # if c == 20:
            #     break
        except Exception as e:
            print("Error in example: ", example)

    print("No answer found: ", no_answer_found)
    save_to_disk(
        samples,
        os.path.join(save_path, f"{model_name}_collated_data_with_answers.jsonl"),
    )

    # step 3: postprocess data
    with jsonlines.open(
        os.path.join(save_path, f"{model_name}_collated_data_with_answers.jsonl")
    ) as reader:
        data = [
            sample
            for sample in tqdm(reader, desc="Loading data for postprocessing... ")
        ]

        # Load SQuAD dataset
        squad_dataset = load_dataset("squad")
        # Collect all unique QA strings in SQuAD dataset
        squad_examples = set()
        for example in squad_dataset["train"]:
            qa_string = example["question"] + example["answers"]["text"][0]
            squad_examples.add(qa_string)

        c = 0
        with jsonlines.open(
            os.path.join(
                save_path, f"{model_name}_collated_data_with_answers_processed.jsonl"
            ),
            "a",
        ) as writer:
            seen_examples = set()
            for example in tqdm(data, total=len(data), desc="Saving samples ... "):
                question = postprocess_question(example["question"])
                answer = postprocess_answer(example["answers"]["text"][0])
                if question is None or answer is None:
                    # print("Question is None: ", example["question"])
                    continue
                example["question"] = question
                example["answers"]["text"][0] = answer
                qa_string = question + answer
                # remove duplicate examples
                if qa_string not in seen_examples and qa_string not in squad_examples:
                    writer.write(example)
                    seen_examples.add(qa_string)
                    c += 1
                # else:
                # print("Duplicate example: ", example["question"], example["answers"]["text"][0])
                # writer.write(example)

        print("Final sample count: ", c)


if __name__ == "__main__":
    data_path = BASE_PATH + "src/data/squad/few_shot_flan-ul2_thinking/"
    save_path = BASE_PATH + "src/data/squad/"
    model_name = "flan-ul2_thinking"
    postprocess_pipeline(data_path, save_path, model_name)

    # input_file = f"{BASE_PATH}src/data/squad/counterfactual_data_gpt_neox_20b_v2_qg_pipeline_all_data.jsonl"
    # save_file = f"{BASE_PATH}src/data/squad/counterfactual_data_gpt_neox_20b_v2_qg_pipeline_all_data_cleaned.jsonl"

    # remaining_samples(complete_file, subset_file, save_path)

    # remove_duplicate_examples(input_file, save_file)

    # data_type = "counterfactuals"
    # if data_type == "squad":
    #     # load squad data
    #     dataset = load_dataset("squad", "plain_text")
    #     train_data = dataset["train"]
    #     data = [sample for sample in tqdm(train_data, total=len(train_data), desc="Loading SQuAD data ... ")]
    # elif data_type == "counterfactuals":
    #     # read in counterfactual data from jsonl file
    #     with jsonlines.open(f"{BASE_PATH}src/data/squad/counterfactual_data_GPT-NeoXT-Chat-Base-20B_qg_pipeline_remaining_final.jsonl") as reader:
    #         data = [sample for sample in tqdm(reader, desc="Loading Counterfactual data ... ")]
    #
    # # Load SQuAD dataset
    # squad_dataset = load_dataset("squad")
    #
    # # Collect all unique QA strings in SQuAD dataset
    # squad_examples = set()
    # for example in squad_dataset["train"]:
    #     qa_string = example["question"] + example["answers"]["text"][0]
    #     squad_examples.add(qa_string)
    #
    # c = 0
    # with jsonlines.open(f"{BASE_PATH}src/data/squad/counterfactual_data_GPT-NeoXT-Chat-Base-20B_qg_pipeline_remaining_final_cleaned.jsonl",
    #                     "a") as writer:
    #     seen_examples = set()
    #     for example in tqdm(data, total=len(data), desc="Saving samples ... "):
    #         question = postprocess_question(example["question"])
    #         answer = postprocess_answer(example["answers"]["text"][0])
    #         if question is None or answer is None:
    #             # print("Question is None: ", example["question"])
    #             continue
    #         example["question"] = question
    #         example["answers"]["text"][0] = answer
    #         qa_string = question + answer
    #         # remove duplicate examples
    #         if qa_string not in seen_examples and qa_string not in squad_examples:
    #             writer.write(example)
    #             seen_examples.add(qa_string)
    #             c += 1
    #         # else:
    #             # print("Duplicate example: ", example["question"], example["answers"]["text"][0])
    #         # writer.write(example)
    # print("Count: ", c)
